import os
import json
import logging
from openai import AsyncAzureOpenAI
from prompts import prompts

logger = logging.getLogger(__name__)

AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")

azure_openai = AsyncAzureOpenAI(
    api_key=AZURE_OPENAI_API_KEY,
    api_version="2023-05-15",
    azure_endpoint=AZURE_OPENAI_ENDPOINT
)

async def process_query(user_query, history):
    """
    Calls Azure OpenAI to determine the next action:
    - If missing parameters, returns a structured follow-up question.
    - If an NLP response is needed, returns a structured message.
    - If ready for OpenSearch, returns tool_calls.
    """
    messages = [
        {"role": "system", "content": prompts["initial_prompt"]}
    ] + history + [{"role": "user", "content": user_query}]
    
    try:
        response = await azure_openai.chat.completions.create(
            model="ai-coe-gpt4-8k-analyze",
            messages=messages,
            temperature=0.7
        )
        
        ai_response = response.choices[0].message.content
        logger.info(f"Raw LLM response: {ai_response}")

        # Convert LLM response to Python dict
        parsed_response = json.loads(ai_response)

        # Validate response_type
        if "response_type" not in parsed_response:
            return {
                "response_type": "message",
                "message": {
                    "text": "Invalid AI response format.",
                    "context": "error"
                }
            }

        return parsed_response  # Returning Python dict (FastAPI auto-converts to JSON)

    except json.JSONDecodeError:
        logger.error("LLM response is not valid JSON.")
        return {
            "response_type": "message",
            "message": {
                "text": "The AI response could not be processed.",
                "context": "error"
            }
        }

    except Exception as e:
        logger.error(f"Error processing query: {str(e)}")
        return {
            "response_type": "message",
            "message": {
                "text": "AI processing failed.",
                "context": "error"
            }
        }

You're absolutely right! The **LLM does not have access to OpenSearch**, so the `"did_you_mean"` logic must be handled **entirely in the backend** before returning a response.

---

## **üîπ Updated Approach**
1. **User enters a query**.
2. **Check OpenSearch for an exact match**:
   - If a match is found ‚Üí Proceed as normal.
   - If no match is found ‚Üí Perform a **fuzzy search** to find similar options.
3. **If similar options exist**, return a `"did_you_mean"` response to the user.

---

## **‚úÖ Updated `ai_gateway.py`**
- **Now detects when OpenSearch has no exact match** and suggests `"did_you_mean"` before querying the LLM.

```python
import os
import json
import logging
from openai import AsyncAzureOpenAI
from prompts import prompts
from services.opensearch import query_valid_options, query_did_you_mean

logger = logging.getLogger(__name__)

AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")

azure_openai = AsyncAzureOpenAI(
    api_key=AZURE_OPENAI_API_KEY,
    api_version="2023-05-15",
    azure_endpoint=AZURE_OPENAI_ENDPOINT
)

async def process_query(user_query, history):
    """
    Calls OpenSearch first to check for exact matches.
    - If no exact match, perform fuzzy search and return "did_you_mean".
    - Otherwise, proceed with normal LLM processing.
    """
    
    # First, check OpenSearch for valid matches
    exact_match = await query_valid_options(user_query)
    
    if not exact_match:  # No exact match, try fuzzy search
        fuzzy_matches = await query_did_you_mean(user_query)
        
        if fuzzy_matches:
            return {
                "response_type": "did_you_mean",
                "did_you_mean": {
                    "question": "Did you mean one of these?",
                    "options": fuzzy_matches
                }
            }
    
    # If an exact match exists, proceed with LLM processing
    messages = [
        {"role": "system", "content": prompts["initial_prompt"]}
    ] + history + [{"role": "user", "content": user_query}]
    
    try:
        response = await azure_openai.chat.completions.create(
            model="ai-coe-gpt4-8k-analyze",
            messages=messages,
            temperature=0.7
        )
        
        ai_response = response.choices[0].message.content
        logger.info(f"Raw LLM response: {ai_response}")

        # Convert LLM response to Python dict
        parsed_response = json.loads(ai_response)

        # Validate response_type
        if "response_type" not in parsed_response:
            return {
                "response_type": "message",
                "message": {
                    "text": "Invalid AI response format.",
                    "context": "error"
                }
            }

        return parsed_response  # Returning Python dict (FastAPI auto-converts to JSON)

    except json.JSONDecodeError:
        logger.error("LLM response is not valid JSON.")
        return {
            "response_type": "message",
            "message": {
                "text": "The AI response could not be processed.",
                "context": "error"
            }
        }

    except Exception as e:
        logger.error(f"Error processing query: {str(e)}")
        return {
            "response_type": "message",
            "message": {
                "text": "AI processing failed.",
                "context": "error"
            }
        }
```

---

## **‚úÖ Updated `opensearch.py`**
- **Performs a fuzzy search** if no exact match is found.

```python
import os
import requests
import logging

logger = logging.getLogger(__name__)

OPENSEARCH_URL = os.getenv("OPENSEARCH_URL", "http://localhost:9200/fps_um/_search")

async def query_valid_options(user_input):
    """
    Checks if a user's input has an exact match in OpenSearch.
    """
    query = {
        "size": 1,
        "_source": ["formulary_name"],
        "query": {
            "match_phrase": {
                "formulary_name.keyword": user_input
            }
        }
    }

    response = requests.post(OPENSEARCH_URL, json=query)
    
    if response.status_code == 200:
        data = response.json()
        hits = data.get("hits", {}).get("hits", [])
        
        if hits:
            return True  # Exact match found
        return False  # No exact match

    return False  # Error or no match

async def query_did_you_mean(user_input):
    """
    Searches OpenSearch for similar terms when user input does not match exactly.
    """
    query = {
        "size": 5,  # Limit results
        "_source": ["formulary_name"],
        "query": {
            "fuzzy": {  # Use fuzzy search to find close matches
                "formulary_name": {
                    "value": user_input,
                    "fuzziness": "AUTO"
                }
            }
        }
    }

    response = requests.post(OPENSEARCH_URL, json=query)
    
    if response.status_code == 200:
        data = response.json()
        hits = data.get("hits", {}).get("hits", [])
        options = list(set(hit["_source"]["formulary_name"] for hit in hits if "formulary_name" in hit["_source"]))
        return sorted(options)  # Returning sorted list of unique matches
    else:
        return []
```

---

## **3Ô∏è‚É£ Example Scenarios**

### **‚úÖ Scenario 1: User Makes a Typo**
üë§ **User**: *"What are the drugs under Expres Scipts?"*  
üîç **OpenSearch finds no exact match, but fuzzy search suggests options**  
ü§ñ **Bot Response (JSON)**:
```json
{
  "response_type": "did_you_mean",
  "did_you_mean": {
    "question": "Did you mean one of these?",
    "options": ["Express Scripts", "BlueCross", "Aetna"]
  }
}
```

---

### **‚úÖ Scenario 2: User Provides a Correct Formulary**
üë§ **User**: *"What are the drugs under Express Scripts?"*  
üîç **OpenSearch confirms an exact match**  
ü§ñ **Bot proceeds with normal query execution**:
```json
{
  "response_type": "tool_calls",
  "tool_calls": [
    {
      "tool": "query_drug_list_for_formulary",
      "parameters": {
        "formulary_name": "Express Scripts",
        "year": 2023
      }
    }
  ]
}
```

---

### **‚úÖ Scenario 3: User Misses a Required Field (Follow-Up)**
üë§ **User**: *"What are the drugs under Express Scripts?"*  
üîç **OpenSearch confirms a match, but no year is provided**  
ü§ñ **Bot asks for missing information**:
```json
{
  "response_type": "follow_up",
  "follow_up": {
    "question": "For which year do you need the drug list?",
    "options": ["2021", "2022", "2023"]
  }
}
```

---

## **üöÄ Summary of Fixes**
‚úî **LLM no longer guesses `"did_you_mean"`‚Äîwe handle it in OpenSearch**  
‚úî **If no exact match, OpenSearch performs a fuzzy search**  
‚úî **User gets a `"did_you_mean"` response with valid options**  
‚úî **Bot only queries LLM when we have a valid match**  

üöÄ **Now your bot can suggest corrections for typos using OpenSearch!** Let me know if you need refinements! üéØ

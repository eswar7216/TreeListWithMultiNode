Yes! You can **rely on the LLM** to handle `"did_you_mean"` confirmations and selections instead of managing it explicitly in code. This would allow the **bot prompt itself** to decide:
- If the user **accepts the suggested option** (saying "Yes" or "Confirm").
- If the user **selects one of the multiple options**.
- If the user **provides an invalid response**, ask again.

---

## **üîπ How to Do This Using LLM**
### **1Ô∏è‚É£ Modify `prompts.yaml` to Include "Did You Mean" Handling**
We will enhance the **LLM‚Äôs ability to understand user responses to `"did_you_mean"`**.

```yaml
prompts:
  context_prompt: |
    You are an AI assistant that determines the intent of a user query.

    **Your response must be in JSON format and include a "context" key.**
    
    - If the user is greeting (e.g., "Hello", "Hi", "Hey"), respond:
      {
        "context": "greeting"
      }

    - If the user is asking a general NLP question (e.g., "How does formulary placement work?", "What is WAC?", "Tell me about Express Scripts"), respond:
      {
        "context": "nlp",
        "message": "Formulary placement determines where a drug is listed in an insurance plan. Would you like to ask about a specific formulary?"
      }

    - If the user is asking about a formulary search (e.g., "What is the WAC for Lipitor?"), extract **only the relevant entities** and return:
      {
        "context": "formulary_search",
        "entity_type": "formulary_name",
        "entity_value": "Express Scripts",
        "tool": "query_total_wac",
        "parameters": {
          "formulary_name": "Express Scripts",
          "year": "2023",
          "brand_name": "Lipitor"
        },
        "missing_parameters": ["year"]  // If missing details
      }

    - If OpenSearch provides a `"did_you_mean"` suggestion and the user responds:
      - If there is only **one** option and the user says "Yes" or "Confirm":
        {
          "context": "did_you_mean",
          "selected_value": "<option_provided>",
          "confirmed": true
        }
      - If there are **multiple** options and the user selects one:
        {
          "context": "did_you_mean",
          "selected_value": "<selected_option>",
          "confirmed": true
        }
      - If the user provides an **invalid response** (not Yes/Confirm or a valid option):
        {
          "context": "did_you_mean",
          "selected_value": null,
          "confirmed": false,
          "message": "I didn't understand your selection. Please choose a valid option."
        }

    - If the query is unclear, respond:
      {
        "context": "unknown",
        "message": "I'm not sure I understood your request. Can you clarify?"
      }

    **Always return JSON. Never return plain text.**
```

‚úÖ **What changed?**
- The LLM **understands when a user confirms ("Yes")** or selects from multiple options.
- If the user **responds incorrectly**, the LLM itself asks them to reselect.
- The bot **doesn't have to check manually**‚ÄîLLM now determines `"did_you_mean"` selection.

---

### **2Ô∏è‚É£ Modify `process_query()` in `ai_gateway.py`**
Instead of handling `"did_you_mean"` responses manually, we **let the LLM handle it**.

```python
async def process_query(user_query, history):
    """
    Determines the context of the query before deciding whether to:
    - Process an NLP question
    - Query OpenSearch for exact/fuzzy matches
    - Handle "Did You Mean?" responses automatically using LLM
    - Perform a follow-up if necessary
    """

    # Step 1: Let LLM determine the intent
    context_result = await derive_context(user_query, history)
    context = context_result.get("context")

    # Handle User Response to "Did You Mean?"
    if context == "did_you_mean":
        selected_value = context_result.get("selected_value")
        confirmed = context_result.get("confirmed")

        if confirmed and selected_value:
            # Proceed with OpenSearch query using the selected value
            history.append({"role": "user", "content": f"Selected: {selected_value}"})
            return {
                "response_type": "tool_calls",
                "tool_calls": [
                    {
                        "tool": "query_formulary",
                        "parameters": {"formulary_name": selected_value}
                    }
                ]
            }
        
        # If user response is invalid, return the error message from LLM
        return {
            "response_type": "message",
            "message": {
                "text": context_result.get("message", "I couldn't understand your selection."),
                "context": "error"
            }
        }

    # Handle Greetings
    if context == "greeting":
        return {
            "response_type": "message",
            "message": {
                "text": "Hello! How can I assist you today?",
                "context": "greeting"
            }
        }

    # Handle General NLP Queries
    if context == "nlp":
        return {
            "response_type": "message",
            "message": {
                "text": context_result["message"],
                "context": "info"
            }
        }

    # Handle Formulary Search Queries
    if context == "formulary_search":
        entity_type = context_result.get("entity_type")
        entity_value = context_result.get("entity_value")

        if not entity_type or not entity_value:
            return {
                "response_type": "message",
                "message": {
                    "text": "I couldn't determine the entity in your request.",
                    "context": "error"
                }
            }

        # Step 2: Check OpenSearch for exact match using the correct entity type
        exact_match = await query_valid_options(entity_type)

        if not exact_match:  # No exact match, try fuzzy search
            fuzzy_matches = await query_did_you_mean(entity_value)
            
            if fuzzy_matches:
                return {
                    "response_type": "did_you_mean",
                    "did_you_mean": {
                        "question": "Did you mean one of these?",
                        "options": fuzzy_matches,
                        "entity_type": entity_type
                    }
                }

        # Step 3: If an exact match exists, check if follow-up is needed
        missing_parameters = context_result.get("missing_parameters", [])

        if missing_parameters:
            options = await query_valid_options(missing_parameters[0])
            return {
                "response_type": "follow_up",
                "follow_up": {
                    "question": f"Could you provide {missing_parameters[0]}?",
                    "options": options
                }
            }

        # Step 4: If everything is provided, generate tool_calls
        return {
            "response_type": "tool_calls",
            "tool_calls": [
                {
                    "tool": context_result["tool"],
                    "parameters": context_result["parameters"]
                }
            ]
        }

    # Handle Unknown Queries
    if context == "unknown":
        return {
            "response_type": "message",
            "message": {
                "text": context_result["message"],
                "context": "error"
            }
        }

    # Default error handling
    return {
        "response_type": "message",
        "message": {
            "text": "I couldn't determine your request. Please clarify.",
            "context": "error"
        }
    }
```

---

## **‚úÖ Expected Bot Behavior After Fix**
### **Scenario 1: User Selects an Option**
üë§ **User**: *"What are the drugs under Expres Scipts?"*  
üîç **OpenSearch finds no exact match, but fuzzy search suggests options**  
ü§ñ **Bot Response (JSON)**:
```json
{
  "response_type": "did_you_mean",
  "did_you_mean": {
    "question": "Did you mean one of these?",
    "options": ["Express Scripts", "Express RX", "Express Plan"],
    "entity_type": "formulary_name"
  }
}
```
üë§ **User**: *"Express RX"*
ü§ñ **Bot Proceeds with Query Automatically**

---

### **Scenario 2: User Says "Yes" When Only One Option Exists**
üë§ **User**: *"What are the drugs under Expres Scipts?"*  
üîç **OpenSearch finds one possible match: "Express Scripts"**  
üë§ **User**: *"Yes"*
ü§ñ **Bot Proceeds with Query Automatically**

---

## **üöÄ Summary**
‚úî **LLM handles user confirmation and selection**  
‚úî **Bot dynamically processes `"Yes"` responses for one option**  
‚úî **Less manual logic in `ai_gateway.py`‚ÄîLLM decides everything**  

üöÄ **Now, the bot intelligently manages `"did_you_mean"` using LLM!** Let me know if you need refinements! üéØ

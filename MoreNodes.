def format_response_with_llm(results, history):
    """
    Calls Azure OpenAI to reformat OpenSearch results into a user-friendly response, preserving conversation history.
    Handles multiple queries dynamically, ensuring structured responses.
    
    - If response contains a large list, limit to 10 items and notify the user that more results are available.
    - If results contain only one record, return a natural language response.
    - Supports different types of queries without coupling the logic to a single query type.
    """
    if not results or "error" in results[0]:
        return {"response": "I'm sorry, I couldn't find the requested information. Please contact support@example.com."}
    
    reformatted_results = results[:10] if isinstance(results, list) and len(results) > 10 else results
    additional_message = "Showing top 10 results. More data available, refine your search." if isinstance(results, list) and len(results) > 10 else ""
    
    messages = [
        {"role": "system", "content": "Reformat this data into a clear human-readable response. If the list exceeds 10 items, inform the user that only the top 10 results are displayed and more data is available upon request. If the result contains only one record, return a natural language response without mentioning list truncation."},
        {"role": "assistant", "content": str(reformatted_results)},
    ] + [{"role": msg["role"], "content": str(msg["content"])} for msg in history]
    
    try:
        response = azure_openai.chat.completions.create(
            model=AZURE_OPENAI_DEPLOYMENT_NAME,
            messages=messages,
            temperature=0.7
        )
        
        ai_response = response.choices[0].message.content
        logger.info(f"Received formatted AI response: {ai_response}")
        
        parsed_response = json.loads(ai_response)
        if additional_message:
            parsed_response["additional_info"] = additional_message
        return parsed_response
    except json.JSONDecodeError:
        logger.error(f"Failed to parse LLM response: {ai_response}")
        return {"response": "Error formatting response. Here is the raw data:", "data": reformatted_results, "additional_info": additional_message}

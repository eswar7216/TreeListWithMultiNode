Got it! You want the bot to **properly handle all NLP (non-formulary) questions**, not just greetings, while still maintaining structured responses. Here’s how we’ll fix it:

---

## **🔹 Updated Approach**
1. **Determine user intent (context) first using LLM**:
   - **Is it an NLP question?** (General question, greeting, explanation request)
   - **Is it a formulary-related search?** (Structured question needing OpenSearch)
   - **Is it unclear?** (Ask for clarification)

2. **Handle NLP Questions Before Doing Anything Else**:
   - If the user **asks about formularies generally**, return an **informative response**.
   - If the user **greets the bot**, return a **friendly response**.
   - If the user **asks a completely unrelated question**, return a **helpful response**.

3. **For formulary-related questions, proceed with OpenSearch logic**.

---

## **✅ Updated `prompts.yaml`**
Now, the LLM will **correctly classify all NLP questions**.

```yaml
prompts:
  context_prompt: |
    You are an AI assistant that determines the intent of a user query.
    
    **Your response must be in JSON format and include a "context" key.**
    
    - If the user is greeting (e.g., "Hello", "Hi", "Hey"), respond:
      {
        "context": "greeting"
      }

    - If the user is asking a general NLP question (e.g., "How does formulary placement work?", "What is WAC?", "Tell me about Express Scripts"), respond:
      {
        "context": "nlp",
        "message": "Formulary placement determines where a drug is listed in an insurance plan. Would you like to ask about a specific formulary?"
      }

    - If the user is asking about a formulary search (e.g., "What is the WAC for Lipitor?"), respond:
      {
        "context": "formulary_search",
        "entity": "<extracted entity>",
        "tool": "query_total_wac",
        "parameters": {
          "formulary_name": "<extracted formulary>",
          "year": "<extracted year>",
          "brand_name": "<extracted brand>"
        },
        "missing_parameters": ["year"]  // If missing details
      }

    - If the query is unclear, respond:
      {
        "context": "unknown",
        "message": "I'm not sure I understood your request. Can you clarify?"
      }

    **Always return JSON. Never return plain text.**
```

---

## **✅ Updated `ai_gateway.py`**
Now, the bot **first determines if it's an NLP question** before doing anything else.

```python
async def process_query(user_query, history):
    """
    Determines the context of the query before deciding whether to:
    - Process an NLP question
    - Query OpenSearch for exact/fuzzy matches
    - Perform a follow-up if necessary
    - Handle greetings properly
    """
    
    # Step 1: Determine query intent
    context_result = await derive_context(user_query, history)
    context = context_result.get("context")

    # Handle Greetings
    if context == "greeting":
        return {
            "response_type": "message",
            "message": {
                "text": "Hello! How can I assist you today?",
                "context": "greeting"
            }
        }

    # Handle General NLP Queries
    if context == "nlp":
        return {
            "response_type": "message",
            "message": {
                "text": context_result["message"],
                "context": "info"
            }
        }

    # Handle Formulary Search Queries
    if context == "formulary_search":
        entity = context_result.get("entity", "")

        # Step 2: Check OpenSearch for exact match
        exact_match = await query_valid_options(entity)
        
        if not exact_match:  # No exact match, try fuzzy search
            fuzzy_matches = await query_did_you_mean(entity)
            
            if fuzzy_matches:
                return {
                    "response_type": "did_you_mean",
                    "did_you_mean": {
                        "question": "Did you mean one of these?",
                        "options": fuzzy_matches
                    }
                }

        # Step 3: If an exact match exists, check if follow-up is needed
        missing_parameters = context_result.get("missing_parameters", [])

        if missing_parameters:
            options = await query_valid_options(missing_parameters[0])
            return {
                "response_type": "follow_up",
                "follow_up": {
                    "question": f"Could you provide {missing_parameters[0]}?",
                    "options": options
                }
            }

        # Step 4: If everything is provided, generate tool_calls
        return {
            "response_type": "tool_calls",
            "tool_calls": [
                {
                    "tool": context_result["tool"],
                    "parameters": context_result["parameters"]
                }
            ]
        }

    # Handle Unknown Queries
    if context == "unknown":
        return {
            "response_type": "message",
            "message": {
                "text": context_result["message"],
                "context": "error"
            }
        }

    # Default error handling
    return {
        "response_type": "message",
        "message": {
            "text": "I couldn't determine your request. Please clarify.",
            "context": "error"
        }
    }
```

---

## **✅ Example Scenarios**

### **✅ Scenario 1: Greeting**
👤 **User**: *"Hello!"*  
🔍 **LLM detects it's a greeting**  
🤖 **Bot Response (JSON)**:
```json
{
  "response_type": "message",
  "message": {
    "text": "Hello! How can I assist you today?",
    "context": "greeting"
  }
}
```

---

### **✅ Scenario 2: NLP Question (General Knowledge)**
👤 **User**: *"How does formulary placement work?"*  
🔍 **LLM determines it's an NLP query**  
🤖 **Bot Response (JSON)**:
```json
{
  "response_type": "message",
  "message": {
    "text": "Formulary placement determines where a drug is listed in an insurance plan. Would you like to ask about a specific formulary?",
    "context": "info"
  }
}
```

---

### **✅ Scenario 3: NLP Question (Specific Formulary)**
👤 **User**: *"Tell me about Express Scripts."*  
🔍 **LLM determines it's an NLP query**  
🤖 **Bot Response (JSON)**:
```json
{
  "response_type": "message",
  "message": {
    "text": "Express Scripts is a pharmacy benefit manager that administers drug benefit programs. Would you like to search for a specific drug?",
    "context": "info"
  }
}
```

---

### **✅ Scenario 4: Did You Mean?**
👤 **User**: *"What are the drugs under Expres Scipts?"*  
🔍 **LLM detects it's a formulary search**  
🔍 **OpenSearch finds no exact match, but fuzzy search suggests options**  
🤖 **Bot Response (JSON)**:
```json
{
  "response_type": "did_you_mean",
  "did_you_mean": {
    "question": "Did you mean one of these?",
    "options": ["Express Scripts", "BlueCross", "Aetna"]
  }
}
```

---

### **✅ Scenario 5: Follow-Up**
👤 **User**: *"What is the WAC for Lipitor?"*  
🔍 **LLM detects a formulary search**  
🔍 **OpenSearch confirms a match, but year is missing**  
🤖 **Bot Response (JSON)**:
```json
{
  "response_type": "follow_up",
  "follow_up": {
    "question": "Could you provide the year?",
    "options": ["2021", "2022", "2023"]
  }
}
```

---

### **✅ Scenario 6: Full Query**
👤 **User**: *"What is the WAC for Lipitor under Express Scripts in 2023?"*  
🔍 **LLM confirms all required parameters**  
🔍 **OpenSearch finds an exact match**  
🤖 **Bot Calls OpenSearch**:
```json
{
  "response_type": "tool_calls",
  "tool_calls": [
    {
      "tool": "query_total_wac",
      "parameters": {
        "formulary_name": "Express Scripts",
        "year": 2023,
        "brand_name": "Lipitor"
      }
    }
  ]
}
```

---

### **🚀 Summary of Fixes**
✔ **Now properly handles all NLP questions, not just greetings**  
✔ **Prevents the bot from returning "unknown" for general questions**  
✔ **Maintains structured JSON responses**  
✔ **More interactive and intelligent responses**  

🚀 **Now your bot is fully intelligent and interactive!** Let me know if you need further refinements! 🎯

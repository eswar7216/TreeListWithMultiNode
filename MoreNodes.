import os
import json
import time
import pandas as pd
from dotenv import load_dotenv, find_dotenv
import openai


# Load environment variables and configure SSL certificate
def initialize_environment():
    """
    Initializes environment variables and sets up SSL certificate.
    """
    load_dotenv(find_dotenv())
    os.environ['SSL_CERT_FILE'] = '/users/eswar/certs/ert.pem'  # Set SSL certificate path
    openai.api_key = os.getenv('OPENAI_API_KEY')                # Load OpenAI API key


# Function to create API prompts
def create_prompt(conversations):
    """
    Generates a prompt with system instructions and input data.
    """
    system_message = """
    sentiment: Provide customer sentiment either Positive/Negative.

    summary: Provide a concise summary that clearly outlines the customer's inquiry and the agent's actions.
    Limit the summary's length to ensure accuracy and clarity.

    subject: Generate a subject line that encapsulates the main theme or focus of the conversation.

    transcript: Include the original transcript and replace ALL personally identifiable information 
    (i.e., ALL names including part or full names, addresses including states and cities, phone numbers) 
    replaced with '****', dates should remain visible.

    Respond with only the following JSON format and nothing else. Use '###' as a delimiter between JSON objects:
    {
        "sentiment": "",
        "summary": "",
        "subject": "",
        "transcript": ""
    }
    """
    return f'{system_message}\n{conversations}'


# Function to call OpenAI API with retries
def call_openai_api(prompt, retries=10, delay=60):
    """
    Makes a call to the OpenAI API with retry logic in case of failures.
    """
    for attempt in range(retries):
        try:
            print(f"Attempt {attempt + 1}/{retries}: Making call to OpenAI API...")
            response = openai.Completion.create(
                engine="ai-coe-gpt4-32k",
                prompt=prompt,
                max_tokens=31000
            )
            return response['choices'][0]['message']['content'].strip()
        except Exception as e:
            print(f"Error: {e}")
            if attempt < retries - 1:
                print(f"Retrying in {delay} seconds...")
                time.sleep(delay)
            else:
                print("Max retries reached. Exiting.")
                return None


# Function to process API response
def parse_response(response_content):
    """
    Parses the API response content and converts it into JSON objects.
    """
    if not response_content:
        return []

    analysis_list = []
    json_objects = response_content.split("###")
    for obj in json_objects:
        obj = obj.strip()
        if obj:
            try:
                analysis = json.loads(obj)
                analysis_list.append(analysis)
            except json.JSONDecodeError as e:
                print("JSON Decode Error:", e)
    return analysis_list


# Function to process an Excel file in batches
def process_excel_file(file_path, batch_size=5):
    """
    Processes an Excel file in batches, sends data to OpenAI API, and saves the results.
    """
    # Read input data
    df = pd.read_excel(file_path, header=None, names=['RawData'])
    df = df[1:]  # Skip the first row if metadata or headers exist

    # Process in batches
    for batch_start in range(0, len(df), batch_size):
        batch_df = df.iloc[batch_start:batch_start + batch_size]
        conversations = "\n\n".join(batch_df['RawData'])

        # Generate prompt and call API
        prompt = create_prompt(conversations)
        response_content = call_openai_api(prompt)

        # Parse API response
        analysis_list = parse_response(response_content)
        print(f"Processed batch {batch_start // batch_size + 1}: Analysis received")

        # Prepare batch results
        batch_results = []
        for idx, analysis in enumerate(analysis_list):
            id_value = batch_start + idx + 1
            batch_results.append([id_value, analysis])

        # Save batch results
        save_results_to_csv(batch_results, batch_start == 0)

        # Pause before next batch
        print("Pausing for 60 seconds before next API call...")
        time.sleep(60)

    print("Processing complete. Results saved to 'output/output_results.csv'")


# Function to save results to CSV
def save_results_to_csv(batch_results, is_first_batch):
    """
    Saves batch results to a CSV file in append mode.
    """
    output_file = 'output/output_results.csv'
    batch_results_df = pd.DataFrame(batch_results, columns=['ID', 'Analysis'])
    batch_results_df.to_csv(output_file, mode='a', header=is_first_batch, index=False)
    print(f"Results stored in '{output_file}'")


# Main function
if __name__ == "__main__":
    # Initialize environment and configuration
    initialize_environment()

    # File path for input data
    excel_file_path = 'data/input_transcripts.xlsx'

    # Process Excel file
    process_excel_file(excel_file_path)